{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising Auto Encoder\n",
    "\n",
    "By: Chengyi (Jeff) Chen\n",
    "\n",
    "## Objective\n",
    "\n",
    "In this notebook, we will accomplish the following:\n",
    "1. Generate noisy images from this [repo](https://github.com/Belval/TextRecognitionDataGenerator) using the names of the currently active businesses in LA\n",
    "2. Implement a denoising auto encoder to clean / repair the augmented / noisy images so that we can feed the cleaned images into an OCR (Google's) for text recognition\n",
    "\n",
    "## Motivation\n",
    "\n",
    "- In order to identify the diversity demographic makeup of currently operating businesses in different parts of LA.\n",
    "\n",
    "## Data\n",
    "\n",
    "- To generate a list of relevant images like store names in LA, we will first pull the list of active businesses in LA from data.lacity.org and feed those names into our image generator, subsequently augmenting the simulated store sign images to be blocked by obstacles such as branches, trees, lamposts, etc... so that we have a representative training set that will \\be fed into our denoising autoencoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffchenchengyi/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# General Utilities\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import subprocess\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "\n",
    "# ML / Deep learning Utilities\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from pylab import rcParams\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-paper')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Downloading Dataset\n",
    "__We will first grab the list of all active businesses in LA from [data.lacity.org](https://dev.socrata.com/foundry/data.lacity.org/ngkp-kqkn)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create a new folder\n",
    "def mkdir(path):\n",
    "    try: \n",
    "        os.makedirs(path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(path):\n",
    "            raise\n",
    "        else:\n",
    "            print(\"(%s) already exists\" % (path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data into data/lacity in the current directory\n",
    "# run !ls data/lacity to see the csv it downloaded\n",
    "!wget --directory-prefix=data/lacity/ -Nq https://data.lacity.org/api/views/6rrh-rzua/rows.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare directory to write results and file to read data from\n",
    "LACITY_DATA_LOC = 'data/lacity/rows.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's checkout the dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCATION ACCOUNT #</th>\n",
       "      <th>BUSINESS NAME</th>\n",
       "      <th>DBA NAME</th>\n",
       "      <th>STREET ADDRESS</th>\n",
       "      <th>CITY</th>\n",
       "      <th>ZIP CODE</th>\n",
       "      <th>LOCATION DESCRIPTION</th>\n",
       "      <th>MAILING ADDRESS</th>\n",
       "      <th>MAILING CITY</th>\n",
       "      <th>MAILING ZIP CODE</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>PRIMARY NAICS DESCRIPTION</th>\n",
       "      <th>COUNCIL DISTRICT</th>\n",
       "      <th>LOCATION START DATE</th>\n",
       "      <th>LOCATION END DATE</th>\n",
       "      <th>LOCATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000000115-0001-3</td>\n",
       "      <td>VINCENZO LABELLA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>521 SWARTHMORE AVENUE</td>\n",
       "      <td>PACIFIC PALISADES</td>\n",
       "      <td>90272-4350</td>\n",
       "      <td>521 SWARTHMORE 90272-4350</td>\n",
       "      <td>521 SWARTHMORE AVENUE</td>\n",
       "      <td>PACIFIC PALISADES</td>\n",
       "      <td>90272-4350</td>\n",
       "      <td>561500.0</td>\n",
       "      <td>Travel arrangement &amp; reservation services</td>\n",
       "      <td>11</td>\n",
       "      <td>01/01/1990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000000150-0001-5</td>\n",
       "      <td>A A OFICINA CENTRAL HISPANA DE LOS ANGELES /C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015 W TEMPLE STREET</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>90026-4913</td>\n",
       "      <td>2015 TEMPLE 90026-4913</td>\n",
       "      <td>2607 VAN BUREN PLACE</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>90007-2129</td>\n",
       "      <td>611000.0</td>\n",
       "      <td>Educational services (including schools, colle...</td>\n",
       "      <td>13</td>\n",
       "      <td>01/01/1991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000000156-0001-2</td>\n",
       "      <td>SPRINGBOARD NON-PROFIT CONSUMER CREDIT MANAGEMENT</td>\n",
       "      <td>MONEY MANAGEMENT INTERNATIONAL</td>\n",
       "      <td>1605 W OLYMPIC BLVD #9023</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>90015-3828</td>\n",
       "      <td>1605 OLYMPIC 90015-3828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>523900.0</td>\n",
       "      <td>Other financial investment activities (includi...</td>\n",
       "      <td>1</td>\n",
       "      <td>02/01/1999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000000247-0001-1</td>\n",
       "      <td>A A OFICINA CENTRAL HISPANA DE LOS ANGELES /C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3806 W PICO BLVD</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>90019-4304</td>\n",
       "      <td>3806 PICO 90019-4304</td>\n",
       "      <td>2607 VAN BUREN PLACE</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>90007-2129</td>\n",
       "      <td>611000.0</td>\n",
       "      <td>Educational services (including schools, colle...</td>\n",
       "      <td>10</td>\n",
       "      <td>01/01/1991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000000267-0001-9</td>\n",
       "      <td>A A OFICINA CENTRAL HISPANA DE LOS ANGELES /C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3115 VENICE BLVD</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>90019-6238</td>\n",
       "      <td>3115 VENICE 90019-6238</td>\n",
       "      <td>2607 VAN BUREN PLACE</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>90007-2129</td>\n",
       "      <td>611000.0</td>\n",
       "      <td>Educational services (including schools, colle...</td>\n",
       "      <td>10</td>\n",
       "      <td>01/01/1991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LOCATION ACCOUNT #                                      BUSINESS NAME  \\\n",
       "0  0000000115-0001-3                                   VINCENZO LABELLA   \n",
       "1  0000000150-0001-5      A A OFICINA CENTRAL HISPANA DE LOS ANGELES /C   \n",
       "2  0000000156-0001-2  SPRINGBOARD NON-PROFIT CONSUMER CREDIT MANAGEMENT   \n",
       "3  0000000247-0001-1      A A OFICINA CENTRAL HISPANA DE LOS ANGELES /C   \n",
       "4  0000000267-0001-9      A A OFICINA CENTRAL HISPANA DE LOS ANGELES /C   \n",
       "\n",
       "                         DBA NAME             STREET ADDRESS  \\\n",
       "0                             NaN      521 SWARTHMORE AVENUE   \n",
       "1                             NaN       2015 W TEMPLE STREET   \n",
       "2  MONEY MANAGEMENT INTERNATIONAL  1605 W OLYMPIC BLVD #9023   \n",
       "3                             NaN           3806 W PICO BLVD   \n",
       "4                             NaN           3115 VENICE BLVD   \n",
       "\n",
       "                CITY    ZIP CODE       LOCATION DESCRIPTION  \\\n",
       "0  PACIFIC PALISADES  90272-4350  521 SWARTHMORE 90272-4350   \n",
       "1        LOS ANGELES  90026-4913     2015 TEMPLE 90026-4913   \n",
       "2        LOS ANGELES  90015-3828    1605 OLYMPIC 90015-3828   \n",
       "3        LOS ANGELES  90019-4304       3806 PICO 90019-4304   \n",
       "4        LOS ANGELES  90019-6238     3115 VENICE 90019-6238   \n",
       "\n",
       "         MAILING ADDRESS       MAILING CITY MAILING ZIP CODE     NAICS  \\\n",
       "0  521 SWARTHMORE AVENUE  PACIFIC PALISADES       90272-4350  561500.0   \n",
       "1   2607 VAN BUREN PLACE        LOS ANGELES       90007-2129  611000.0   \n",
       "2                    NaN                NaN              NaN  523900.0   \n",
       "3   2607 VAN BUREN PLACE        LOS ANGELES       90007-2129  611000.0   \n",
       "4   2607 VAN BUREN PLACE        LOS ANGELES       90007-2129  611000.0   \n",
       "\n",
       "                           PRIMARY NAICS DESCRIPTION  COUNCIL DISTRICT  \\\n",
       "0          Travel arrangement & reservation services                11   \n",
       "1  Educational services (including schools, colle...                13   \n",
       "2  Other financial investment activities (includi...                 1   \n",
       "3  Educational services (including schools, colle...                10   \n",
       "4  Educational services (including schools, colle...                10   \n",
       "\n",
       "  LOCATION START DATE  LOCATION END DATE LOCATION  \n",
       "0          01/01/1990                NaN      NaN  \n",
       "1          01/01/1991                NaN      NaN  \n",
       "2          02/01/1999                NaN      NaN  \n",
       "3          01/01/1991                NaN      NaN  \n",
       "4          01/01/1991                NaN      NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv(LACITY_DATA_LOC)\n",
    "raw_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Seems like Business name is what we really need as it is the title that would likely appear on the storefront__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     VINCENZO LABELLA\n",
       "1        A A OFICINA CENTRAL HISPANA DE LOS ANGELES /C\n",
       "2    SPRINGBOARD NON-PROFIT CONSUMER CREDIT MANAGEMENT\n",
       "3        A A OFICINA CENTRAL HISPANA DE LOS ANGELES /C\n",
       "4        A A OFICINA CENTRAL HISPANA DE LOS ANGELES /C\n",
       "5        A A OFICINA CENTRAL HISPANA DE LOS ANGELES /C\n",
       "6        A A OFICINA CENTRAL HISPANA DE LOS ANGELES /C\n",
       "7        A A OFICINA CENTRAL HISPANA DE LOS ANGELES /C\n",
       "8        A A OFICINA CENTRAL HISPANA DE LOS ANGELES /C\n",
       "9                                     CORALIE WHITCOMB\n",
       "Name: BUSINESS NAME, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['BUSINESS NAME'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__There are duplicate Business names in the dataset, so let's remove them and store in a list__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of active businesses in LA: 482884\n"
     ]
    }
   ],
   "source": [
    "# Getting only the unique business names and removing the weird \"/C\"s\n",
    "business_names = [name[:-3] if name[-3:] == ' /C' or name[-2:] == '/C' else name for name in raw_df['BUSINESS NAME'].unique()]\n",
    "\n",
    "# TODO: Escaping the \"/\" in the names to prevent it \n",
    "# from messing up the name format later on\n",
    "'''\n",
    "    Use Regex to escape \"/\" because the TextRecognitionDataGeneretor can't escape it\n",
    "'''\n",
    "\n",
    "# How many active businesses in LA\n",
    "print('Number of active businesses in LA: %d' % len(business_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's write these names into a .txt file which we will use for the image generation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of .txt files that can be used \n",
    "# for the text image data generation\n",
    "DICT_LOC = './dicts/sp.txt'\n",
    "\n",
    "# Remove any old la_active_business_names.txt\n",
    "subprocess.call(['rm', '-rf', DICT_LOC])\n",
    "\n",
    "# Writing all the active LA business names\n",
    "# into the .txt file\n",
    "with open(DICT_LOC, 'w') as f:\n",
    "    for idx, name in enumerate(business_names):\n",
    "        f.write(\"%s\\n\" % name)\n",
    "        \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Generation\n",
    "__Now let's use the [TextRecognitionDataGenerator](https://github.com/Belval/TextRecognitionDataGenerator) to generate images of those active LA Business names. Firstly, we will create 8 images for each business name and store it in a folder for original images. Secondly, we will augment all of the images with random rotations, line streaks to cover parts of the image, etc... and store them in a folder for altered images which we will use to feed into the denoising auto encoder as the input. The original images will be treated as the true outputs that our denoised images will be compared to, determing the loss.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory of where our training / testing\n",
    "# dataset will be stored\n",
    "TRAIN_LOC = './data/training'\n",
    "TEST_LOC = './data/testing'\n",
    "\n",
    "# Remove any old data for training / testing\n",
    "subprocess.call(['rm', '-rf', TRAIN_LOC])\n",
    "subprocess.call(['rm', '-rf', TEST_LOC]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's generate the original images for training and test set - we would like a 80% training, 20% testing split for the data, so with 482,884 business names, and 8 images for each business name in the original image set, we would generate 3,863,072 images for our training set and 965,768 images for our testing set (P.S. Now I'm only creating 10,000 images to try out)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.7 ms, sys: 10.3 ms, total: 12 ms\n",
      "Wall time: 79.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create new directories for the augmented images\n",
    "mkdir(TRAIN_LOC + '/original')\n",
    "mkdir(TEST_LOC + '/original')\n",
    "\n",
    "# Directory of the run.py file for TextRecognitionDataGenerator\n",
    "# & original images for training\n",
    "DATAGEN_LOC = '../TextRecognitionDataGenerator/TextRecognitionDataGenerator/run.py'\n",
    "TRAIN_SIZE = 8000\n",
    "TEST_SIZE = 2000\n",
    "\n",
    "# Original TRAINING images are named [INDEX].jpg\n",
    "subprocess.call(['python', \n",
    "                 DATAGEN_LOC, \n",
    "                 '--output_dir', \n",
    "                 TRAIN_LOC + '/original', \n",
    "                 '-na' , '2' ,\n",
    "                 '-l', 'sp', \n",
    "                 '-c', str(TRAIN_SIZE), \n",
    "                 '-w', '1']);\n",
    "\n",
    "# Original TESTING images are named [INDEX].jpg\n",
    "subprocess.call(['python', \n",
    "                 DATAGEN_LOC, \n",
    "                 '--output_dir', \n",
    "                 TEST_LOC + '/original', \n",
    "                 '-na' , '2' ,\n",
    "                 '-l', 'sp', \n",
    "                 '-c', str(TEST_SIZE), \n",
    "                 '-w', '1']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Augmentation\n",
    "__Now we will perform random augmentations on our original dataset and we will use this to feed into our denoising autoencoder - For every single original image, we will draw a random line in the image that may or may not cover the characters and a rotation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/training/original/0.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-af1ddc0aedbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_LOC\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/original/%d.jpg'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2543\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2544\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/training/original/0.jpg'"
     ]
    }
   ],
   "source": [
    "# Create new directories for the augmented images\n",
    "mkdir(TRAIN_LOC + '/augmented')\n",
    "mkdir(TEST_LOC + '/augmented')\n",
    "\n",
    "# Training set\n",
    "for i in range(TRAIN_SIZE):\n",
    "    img = Image.open(TRAIN_LOC + '/original/%d.jpg' % i).rotate(np.random.randint(20))\n",
    "    w = random.randint(1, img.size[1]/2)\n",
    "    x1 = random.randint(0, img.size[0])\n",
    "    y1 = random.randint(0, img.size[1])\n",
    "    x2 = random.randint(0, img.size[0])\n",
    "    y2 = random.randint(0, img.size[1])\n",
    "    img_draw = ImageDraw.Draw(img)\n",
    "    img_draw.line([(x1, y1), (x2, y2)], width=w, fill='brown')\n",
    "    img.save(TRAIN_LOC + '/augmented/%d.jpg' % i)\n",
    "\n",
    "\n",
    "# Testing set\n",
    "for i in range(TEST_SIZE):\n",
    "    img = Image.open(TEST_LOC + '/original/%d.jpg' % i).rotate(np.random.randint(20))\n",
    "    w = random.randint(1, img.size[1]/2)\n",
    "    x1 = random.randint(0, img.size[0])\n",
    "    y1 = random.randint(0, img.size[1])\n",
    "    x2 = random.randint(0, img.size[0])\n",
    "    y2 = random.randint(0, img.size[1])\n",
    "    img_draw = ImageDraw.Draw(img)\n",
    "    img_draw.line([(x1, y1), (x2, y2)], width=w, fill='brown')\n",
    "    img.save(TEST_LOC + '/augmented/%d.jpg' % i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Pre-processing\n",
    "__Now that we have both the original unobstructed images and the augmented images, we can now take a look at the images as well as reshape them for our denoising auto encoder__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read an example Image from the training set with matplotlib\n",
    "import matplotlib.image as mpimg \n",
    "\n",
    "# Random idx for us to see the original and augmented image\n",
    "rand_idx = random.randint(0, TRAIN_SIZE)\n",
    "  \n",
    "# Output Images Settings\n",
    "rcParams['figure.figsize'] = 20,20\n",
    "fig, ax = plt.subplots(5,2)\n",
    "\n",
    "# Displaying a list of the originals and augmented side by side\n",
    "for row_idx in range(5):\n",
    "    \n",
    "    img_original = mpimg.imread(TRAIN_LOC + '/original/%d.jpg' % (rand_idx + row_idx)) \n",
    "    img_augmented = mpimg.imread(TRAIN_LOC + '/augmented/%d.jpg' % (rand_idx + row_idx)) \n",
    "\n",
    "    # Original Image\n",
    "    ax[row_idx, 0].set_title('Original Image (Used for Decoder Loss)')\n",
    "    ax[row_idx, 0].imshow(img_original)\n",
    "\n",
    "    # Augmented Image\n",
    "    ax[row_idx, 1].set_title('Augmented Image (Fed into Encoder as Input)')\n",
    "    ax[row_idx, 1].imshow(img_augmented)\n",
    "    \n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Since all the images are of different sizes, let's resize them__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Resize and save the images\n",
    "# X_train = \n",
    "# X_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Denoising Auto Encoder Model\n",
    "__We will build our denoising auto encoder now, we use this article as our [reference](https://medium.com/@connectwithghosh/denoising-images-using-an-autoencoder-using-tensorflow-in-python-1e2e62932837)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Number of nodes in each layer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encoder \n",
    "# num_nodes_input = 784\n",
    "# num_nodes_hidden_encoder = 32\n",
    "\n",
    "# # Decoder\n",
    "# num_nodes_hidden_decoder = 32\n",
    "# num_nodes_output  = 784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model Layers__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input Layer: Taking in images of shape 784\n",
    "# input_layer = tf.placeholder('float', [None, num_nodes_input])\n",
    "\n",
    "# # Hidden Layer (Encoder): 784*32 weights and 32 biases\n",
    "# hidden_layer_encoder_vals = {\n",
    "#     'weights': tf.Variable(tf.random_normal([num_nodes_input, num_nodes_hidden_encoder])),\n",
    "#     'biases': tf.Variable(tf.random_normal([num_nodes_hidden_encoder]))  \n",
    "# }\n",
    "\n",
    "# # Hidden layer (Decoder): 32*32 weights and 32 biases\n",
    "# hidden_layer_decoder_vals = {\n",
    "#     'weights': tf.Variable(tf.random_normal([num_nodes_hidden_encoder, num_nodes_hidden_decoder])),\n",
    "#     'biases': tf.Variable(tf.random_normal([num_nodes_hidden_decoder]))  \n",
    "# }\n",
    "\n",
    "# # Output layer: 32*784 weights and 784 biases\n",
    "# output_layer_vals = {\n",
    "#     'weights':tf.Variable(tf.random_normal([num_nodes_hidden_decoder, num_nodes_output])), \n",
    "#     'biases':tf.Variable(tf.random_normal([num_nodes_output])) \n",
    "# }\n",
    "\n",
    "# # Sigmoid activation on input layer values \n",
    "# # and hidden layer of encoder\n",
    "# encoding_layer = tf.nn.sigmoid(\n",
    "#     tf.add(\n",
    "#         tf.matmul(\n",
    "#             input_layer,\n",
    "#             hidden_layer_encoder_vals['weights']\n",
    "#         ),\n",
    "#         hidden_layer_encoder_vals['biases']\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # Sigmoid activation on output of encoding layer \n",
    "# # and the hidden layer of decoder\n",
    "# decoding_layer = tf.nn.sigmoid(\n",
    "#     tf.add(\n",
    "#         tf.matmul(\n",
    "#             layer_1,\n",
    "#             hidden_2_layer_vals['weights']\n",
    "#         ),\n",
    "#         hidden_2_layer_vals['biases']\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # Multiply output of decoding layer with the output layer values\n",
    "# # with Weight and add Bias\n",
    "# output_layer = tf.matmul(\n",
    "#     decoding_layer,\n",
    "#     output_layer_vals['weights']\n",
    "# ) + output_layer_vals['biases']\n",
    "\n",
    "# # Output_true shall have the original image for error calculations\n",
    "# output_true = tf.placeholder('float', [None, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loss Function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Defining our cost function as MSE\n",
    "# mse = tf.reduce_mean(tf.square(output_layer - output_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Optimizer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Defining our optimizer: How fast the model should learn\n",
    "# learn_rate = 0.1\n",
    "# optimizer = tf.train.AdagradOptimizer(learn_rate).minimize(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create Session__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialising session\n",
    "# init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "    \n",
    "#     sess.run(init)\n",
    "    \n",
    "#     # Defining batch size, number of epochs and learning rate\n",
    "#     batch_size = 100  # how many images to use together for training\n",
    "#     hm_epochs =1000    # how many times to go through the entire dataset\n",
    "#     tot_images = X_train.shape[0] # total number of images\n",
    "\n",
    "#     # Running the model for a 10000 epochs taking 100 images in batches\n",
    "#     # total improvement is printed out after each epoch\n",
    "#     for epoch in range(hm_epochs):\n",
    "        \n",
    "#         # Initializing error as 0\n",
    "#         epoch_loss = 0 \n",
    "        \n",
    "#         for i in range(int(tot_images/batch_size)):\n",
    "#             epoch_x = X_train[i * batch_size : (i + 1) * batch_size]\n",
    "#             _, c = sess.run([optimizer, meansq],\\\n",
    "#                    feed_dict={input_layer: epoch_x, \\\n",
    "#                               output_true: epoch_x})\n",
    "#             epoch_loss += c\n",
    "            \n",
    "#         print('Epoch', epoch, '/', hm_epochs, 'loss:',epoch_loss)\n",
    "        \n",
    "#     # Test the Train Model\n",
    "# #     matches = \n",
    "    \n",
    "# #     accuracy = \n",
    "    \n",
    "# #     print(sess.run(accuracy, feed_dict={x: ,\n",
    "# #                                         y_true: }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pick any image\n",
    "# any_image = X_test_noisy[234]\n",
    "\n",
    "# # run it though the autoencoder\n",
    "# output_any_image = sess.run(output_layer,\\\n",
    "#                    feed_dict={input_layer:[any_image]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
